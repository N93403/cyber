#!/usr/bin/env python3
"""
BASIC STATIC MALWARE ANALYZER
Educational tool for static analysis of potentially malicious files
"""

import os
import sys
import hashlib
import argparse
import json
from pathlib import Path
import pefile
import yara
from collections import Counter
import math

class BasicStaticAnalyzer:
    def __init__(self, sample_path):
        self.sample_path = Path(sample_path)
        self.analysis_result = {}
        self.yara_rules = None
        
    def load_yara_rules(self, rules_dir="databases/yara_rules"):
        """Load YARA rules for pattern matching"""
        try:
            rules_path = Path(rules_dir)
            if rules_path.exists():
                # Compile all YARA rules in directory
                rule_files = list(rules_path.glob("*.yar"))
                if rule_files:
                    self.yara_rules = yara.compile(filepaths={
                        str(rule_file): str(rule_file) for rule_file in rule_files
                    })
                    return True
        except Exception as e:
            print(f"‚ö†Ô∏è  YARA rules loading failed: {e}")
        return False
    
    def calculate_entropy(self, data):
        """Calculate Shannon entropy of data"""
        if not data:
            return 0.0
            
        counter = Counter(data)
        entropy = 0.0
        
        for count in counter.values():
            p_x = count / len(data)
            entropy += -p_x * math.log2(p_x)
            
        return entropy
    
    def get_file_signature(self):
        """Calculate file hashes and basic info"""
        try:
            with open(self.sample_path, 'rb') as f:
                file_data = f.read()
            
            self.analysis_result['file_info'] = {
                'filename': self.sample_path.name,
                'file_size': len(file_data),
                'md5': hashlib.md5(file_data).hexdigest(),
                'sha1': hashlib.sha1(file_data).hexdigest(),
                'sha256': hashlib.sha256(file_data).hexdigest(),
                'entropy': self.calculate_entropy(file_data)
            }
            
            return True
        except Exception as e:
            print(f"‚ùå File analysis failed: {e}")
            return False
    
    def analyze_strings(self, min_length=4):
        """Extract and analyze strings from binary"""
        try:
            import subprocess
            
            # Use system strings command
            result = subprocess.run(
                ['strings', '-n', str(min_length), str(self.sample_path)],
                capture_output=True, text=True
            )
            
            strings = result.stdout.split('\n')
            suspicious_strings = []
            
            # Look for suspicious patterns
            suspicious_patterns = [
                'http://', 'https://',  # URLs
                '.exe', '.dll', '.bat',  # Executable extensions
                'cmd.exe', 'powershell',  # Shell references
                'VirtualAlloc', 'CreateRemoteThread',  # Windows API
                'base64', 'decode',  # Obfuscation
                'password', 'key', 'secret',  # Credentials
                'malware', 'virus', 'trojan',  # Self-references
            ]
            
            for string in strings:
                if any(pattern in string.lower() for pattern in suspicious_patterns):
                    suspicious_strings.append(string)
            
            self.analysis_result['strings'] = {
                'total_strings': len(strings),
                'suspicious_strings': suspicious_strings[:50],  # Limit output
                'suspicious_count': len(suspicious_strings)
            }
            
            return True
            
        except Exception as e:
            print(f"‚ùå String analysis failed: {e}")
            return False
    
    def analyze_pe_file(self):
        """Analyze PE files (Windows executables)"""
        try:
            pe = pefile.PE(str(self.sample_path))
            
            pe_info = {
                'machine_type': hex(pe.FILE_HEADER.Machine),
                'timestamp': pe.FILE_HEADER.TimeDateStamp,
                'entry_point': hex(pe.OPTIONAL_HEADER.AddressOfEntryPoint),
                'image_base': hex(pe.OPTIONAL_HEADER.ImageBase),
                'sections': []
            }
            
            # Analyze sections
            for section in pe.sections:
                section_info = {
                    'name': section.Name.decode().rstrip('\x00'),
                    'virtual_size': section.Misc_VirtualSize,
                    'raw_size': section.SizeOfRawData,
                    'entropy': section.get_entropy(),
                    'characteristics': hex(section.Characteristics)
                }
                pe_info['sections'].append(section_info)
            
            # Import analysis
            imports = []
            if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
                for entry in pe.DIRECTORY_ENTRY_IMPORT:
                    for imp in entry.imports:
                        if imp.name:
                            imports.append(imp.name.decode())
            
            pe_info['imports'] = imports[:100]  # Limit output
            pe_info['suspicious_imports'] = [
                imp for imp in imports 
                if any(suspicious in imp.lower() for suspicious in [
                    'virtualalloc', 'createremotethread', 'writeprocessmemory',
                    'setwindowshook', 'getasynckeystate', 'shellexecute'
                ])
            ]
            
            self.analysis_result['pe_analysis'] = pe_info
            return True
            
        except Exception as e:
            print(f"‚ö†Ô∏è  PE analysis failed (may not be PE file): {e}")
            return False
    
    def run_yara_scan(self):
        """Run YARA rules against sample"""
        if not self.yara_rules:
            return False
            
        try:
            matches = self.yara_rules.match(str(self.sample_path))
            
            yara_results = []
            for match in matches:
                yara_results.append({
                    'rule': match.rule,
                    'tags': match.tags,
                    'strings': [str(s) for s in match.strings][:5]  # Limit output
                })
            
            self.analysis_result['yara_matches'] = yara_results
            return True
            
        except Exception as e:
            print(f"‚ùå YARA scan failed: {e}")
            return False
    
    def generate_suspicion_score(self):
        """Generate overall suspicion score"""
        score = 0
        factors = []
        
        # File entropy
        entropy = self.analysis_result.get('file_info', {}).get('entropy', 0)
        if entropy > 7.5:
            score += 30
            factors.append(f"High entropy ({entropy:.2f})")
        
        # Suspicious strings
        suspicious_strings = self.analysis_result.get('strings', {}).get('suspicious_count', 0)
        if suspicious_strings > 10:
            score += min(suspicious_strings * 2, 40)
            factors.append(f"Many suspicious strings ({suspicious_strings})")
        
        # PE analysis factors
        pe_analysis = self.analysis_result.get('pe_analysis', {})
        if pe_analysis:
            # Suspicious imports
            if len(pe_analysis.get('suspicious_imports', [])) > 3:
                score += 20
                factors.append("Suspicious API imports")
            
            # Section anomalies
            for section in pe_analysis.get('sections', []):
                if section['entropy'] > 7.0 and section['raw_size'] > 0:
                    score += 15
                    factors.append(f"High entropy section: {section['name']}")
                    break
        
        # YARA matches
        yara_matches = len(self.analysis_result.get('yara_matches', []))
        if yara_matches > 0:
            score += yara_matches * 10
            factors.append(f"YARA rule matches ({yara_matches})")
        
        self.analysis_result['suspicion_score'] = min(score, 100)
        self.analysis_result['risk_factors'] = factors
        
        # Risk level classification
        if score >= 70:
            risk_level = "HIGH"
        elif score >= 40:
            risk_level = "MEDIUM"
        elif score >= 20:
            risk_level = "LOW"
        else:
            risk_level = "VERY LOW"
        
        self.analysis_result['risk_level'] = risk_level
    
    def analyze(self):
        """Perform complete static analysis"""
        print(f"üîç Analyzing: {self.sample_path.name}")
        print("=" * 50)
        
        # Load YARA rules
        self.load_yara_rules()
        
        # Perform analyses
        analyses = [
            ("File Signature", self.get_file_signature),
            ("String Analysis", self.analyze_strings),
            ("PE Analysis", self.analyze_pe_file),
            ("YARA Scan", self.run_yara_scan)
        ]
        
        for name, analysis_func in analyses:
            print(f"üìä {name}...", end=" ")
            if analysis_func():
                print("‚úÖ")
            else:
                print("‚ùå")
        
        # Generate final assessment
        self.generate_suspicion_score()
        
        return self.analysis_result
    
    def print_report(self):
        """Print analysis report"""
        result = self.analysis_result
        
        print("\n" + "=" * 60)
        print("           STATIC ANALYSIS REPORT")
        print("=" * 60)
        
        # File info
        file_info = result.get('file_info', {})
        print(f"\nüìÅ FILE INFORMATION:")
        print(f"   Name: {file_info.get('filename', 'N/A')}")
        print(f"   Size: {file_info.get('file_size', 0):,} bytes")
        print(f"   MD5: {file_info.get('md5', 'N/A')}")
        print(f"   SHA256: {file_info.get('sha256', 'N/A')}")
        print(f"   Entropy: {file_info.get('entropy', 0):.4f}")
        
        # Strings analysis
        strings_info = result.get('strings', {})
        print(f"\nüî§ STRINGS ANALYSIS:")
        print(f"   Total strings: {strings_info.get('total_strings', 0)}")
        print(f"   Suspicious strings: {strings_info.get('suspicious_count', 0)}")
        
        if strings_info.get('suspicious_strings'):
            print(f"   Top suspicious strings:")
            for string in strings_info['suspicious_strings'][:5]:
                print(f"     - {string[:80]}{'...' if len(string) > 80 else ''}")
        
        # PE Analysis
        if 'pe_analysis' in result:
            pe_info = result['pe_analysis']
            print(f"\nüèóÔ∏è  PE ANALYSIS:")
            print(f"   Entry Point: {pe_info.get('entry_point', 'N/A')}")
            print(f"   Sections: {len(pe_info.get('sections', []))}")
            
            suspicious_imports = pe_info.get('suspicious_imports', [])
            if suspicious_imports:
                print(f"   Suspicious imports: {', '.join(suspicious_imports[:5])}")
        
        # YARA matches
        yara_matches = result.get('yara_matches', [])
        if yara_matches:
            print(f"\nüéØ YARA DETECTIONS:")
            for match in yara_matches:
                print(f"   - {match['rule']} (tags: {', '.join(match['tags'])})")
        
        # Risk assessment
        print(f"\n‚ö†Ô∏è  RISK ASSESSMENT:")
        print(f"   Suspicion Score: {result.get('suspicion_score', 0)}/100")
        print(f"   Risk Level: {result.get('risk_level', 'UNKNOWN')}")
        
        factors = result.get('risk_factors', [])
        if factors:
            print(f"   Risk Factors:")
            for factor in factors:
                print(f"     ‚Ä¢ {factor}")
        
        print("\n" + "=" * 60)
        print("           ANALYSIS COMPLETED")
        print("=" * 60)

def main():
    parser = argparse.ArgumentParser(description='Basic Static Malware Analyzer')
    parser.add_argument('sample', help='Path to the sample file to analyze')
    parser.add_argument('-o', '--output', help='Output JSON report file')
    parser.add_argument('-v', '--verbose', action='store_true', help='Verbose output')
    
    args = parser.parse_args()
    
    # Check if sample exists
    if not os.path.exists(args.sample):
        print(f"‚ùå Sample file not found: {args.sample}")
        sys.exit(1)
    
    # Perform analysis
    analyzer = BasicStaticAnalyzer(args.sample)
    results = analyzer.analyze()
    
    # Print report
    analyzer.print_report()
    
    # Save results if requested
    if args.output:
        with open(args.output, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"\nüíæ Report saved to: {args.output}")

if __name__ == "__main__":
    main()
